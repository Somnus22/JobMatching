{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install spacy\n",
    "#%pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import csv\n",
    "df = pd.read_csv('../data/resumes/Database_Administrator.csv')\n",
    "\n",
    "# merge all clean_text rows into one string variable \n",
    "resume_skills = \" \".join(df['clean_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "#nltk.download('punkt')\n",
    "#nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenise and remove stopwords\n",
    "#stop_words = set(stopwords.words('english'))\n",
    "#resume_tokens = word_tokenize(resume_skills.lower())\n",
    "\n",
    "# convert to set to remove duplicates then back to list\n",
    "#unique_tokens = list(set(resume_tokens))\n",
    "\n",
    "#filtered_tokens = [word for word in resume_tokens if word.isalpha() and word not in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.pipeline import EntityRuler\n",
    "from collections import defaultdict\n",
    "#spacy.cli.download(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    \"\"\"\n",
    "    Remove stop words from the input text.\n",
    "    \n",
    "    Args:\n",
    "        text (str): Input text string\n",
    "        \n",
    "    Returns:\n",
    "        str: Text with stop words removed\n",
    "    \"\"\"\n",
    "    # Download stopwords if not already downloaded\n",
    "    try:\n",
    "        nltk.data.find('corpora/stopwords')\n",
    "    except LookupError:\n",
    "        nltk.download('stopwords')\n",
    "        \n",
    "    # Download punkt tokenizer if not already downloaded\n",
    "    try:\n",
    "        nltk.data.find('tokenizers/punkt')\n",
    "    except LookupError:\n",
    "        nltk.download('punkt')\n",
    "    \n",
    "    # Get English stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    \n",
    "    # Tokenize text\n",
    "    word_tokens = word_tokenize(text.lower())\n",
    "    \n",
    "    # Remove stop words\n",
    "    filtered_words = [word for word in word_tokens if word not in stop_words and word.isalnum()]\n",
    "    \n",
    "    # Join the filtered words back into a string\n",
    "    filtered_text = ' '.join(filtered_words)\n",
    "    \n",
    "    return filtered_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== EXTRACTED ENTITIES ===\n",
      "\n",
      "Programming Language (PL): javascript, python, sql, typescript\n",
      "Framework (FW): django, express, flask, react\n",
      "Database (DB): mongodb, postgresql\n",
      "Cloud Platform (CP): aws, aws certified solutions, aws lambda with, google cloud\n",
      "DevOps (DO): ci/cd, docker, jenkins, kubernetes\n",
      "Data Analysis & Science: tensorflow\n",
      "Project Management (PM): agile, scrum\n",
      "Education Certification (EC): bachelor, certified, csm, master\n",
      "\n",
      "=== LEFTOVER TEXT ===\n",
      "\n",
      "\n",
      "JANE RODRIGUEZ\n",
      "Software Engineer\n",
      "San Francisco, CA | jane.rodriguez@email.com | (555) 123-4567 | linkedin.com/in/janerodriguez\n",
      "\n",
      "PROFESSIONAL SUMMARY\n",
      "-------------------\n",
      "Results-driven Software Engineer with 5+ years of experience developing scalable web applications. Specializing in full-stack development using , , and . Passionate about building intuitive user experiences and optimizing application performance.\n",
      "\n",
      "SKILLS\n",
      "------\n",
      "Programming Languages: , , , , HTML/CSS\n",
      "Frameworks & Libraries: , , , Node.js, .js, Redux\n",
      "Tools & Platforms:  (EC2, S3, Lambda), , , Git, GitHub Actions, \n",
      "Databases: , , Redis\n",
      "Testing: Jest, Pytest, Selenium\n",
      "Methodologies: /, Test-Driven Development, \n",
      "\n",
      "PROFESSIONAL EXPERIENCE\n",
      "----------------------\n",
      "SENIOR SOFTWARE ENGINEER | TechSolutions Inc. | San Francisco, CA | 2021-Present\n",
      "• Developed and maintained a high-traffic e-commerce platform serving 50,000+ daily users\n",
      "• Reduced application load time by 35% through code optimization and implementing Redis caching\n",
      "• Architected and implemented microservices infrastructure, improving system scalability and fault tolerance\n",
      "• Led a team of 5 engineers to deliver new features on time with 98% test coverage\n",
      "• Mentored junior developers and conducted code reviews to ensure code quality and best practices\n",
      "\n",
      "SOFTWARE ENGINEER | DataViz Corp | Oakland, CA | 2018-2021\n",
      "• Created interactive data visualization dashboards using  and D3.js\n",
      "• Designed and implemented RESTful APIs using  and \n",
      "• Migrated legacy monolithic application to a microservices architecture\n",
      "• Automated deployment processes, reducing deployment time from 2 hours to 15 minutes\n",
      "• Implemented unit and integration testing, increasing code coverage from 60% to 90%\n",
      "\n",
      "EDUCATION\n",
      "---------\n",
      " OF SCIENCE IN COMPUTER SCIENCE | University of California, Berkeley | 2018\n",
      "• GPA: 3.8/4.0\n",
      "• Specialization: Artificial Intelligence and Machine Learning\n",
      "• Thesis: \"Optimizing Neural Networks for Mobile Applications\"\n",
      "\n",
      " OF SCIENCE IN COMPUTER ENGINEERING | Stanford University | 2016\n",
      "• GPA: 3.7/4.0\n",
      "• Minor in Mathematics\n",
      "• Dean's List: 6 semesters\n",
      "\n",
      "CERTIFICATIONS\n",
      "-------------\n",
      "•  Architect – Associate\n",
      "•  Professional Data Engineer\n",
      "•    ()\n",
      "\n",
      "PROJECTS\n",
      "--------\n",
      "PERSONAL FINANCE TRACKER | github.com/janerodriguez/finance-tracker\n",
      "• Developed a full-stack application using , Node.js, and \n",
      "• Implemented OAuth2.0 for secure authentication and JWT for authorization\n",
      "• Created data visualization components to track spending habits and budget goals\n",
      "\n",
      "AI CHATBOT ASSISTANT | github.com/janerodriguez/ai-assistant\n",
      "• Built a conversational AI using , , and NLP techniques\n",
      "• Integrated with various APIs to provide real-time information\n",
      "• Deployed on   pipeline through GitHub Actions\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from collections import defaultdict\n",
    "\n",
    "# Expanded regex patterns for better matching\n",
    "patterns = {\n",
    "    \"Programming Language (PL)\": r\"\\b(?:python\\d*|java(?:script)?|c\\+\\+|c#|sql|ruby|go|swift|typescript|r|kotlin)\\b\",\n",
    "    \n",
    "    \"Framework (FW)\": r\"\\b(?:django|flask|spring|react(?:.js)?|angular|vue|express|fastapi|\\.net|laravel)\\b\",\n",
    "    \n",
    "    \"Database (DB)\": r\"\\b(?:sql\\s*server|mysql|postgresql|mongodb|oracle|sqlite|firebase|cassandra|database(?:\\s+\\w+){0,1})\\b\",\n",
    "    \n",
    "    \"Cloud Platform (CP)\": r\"\\b(?:aws(?:\\s+\\w+){0,2}|amazon\\s*web\\s*services|azure|google\\s*cloud|gcp|ibm\\s*cloud|digitalocean|heroku)\\b\",\n",
    "    \n",
    "    \"DevOps (DO)\": r\"\\b(?:docker(?:ized)?|kubernetes|jenkins|terraform|ansible|ci/cd|travis\\s*ci|circleci)\\b\",\n",
    "    \n",
    "    \"Network & Security\": r\"\\b(?:firewall|vpn|ssl/tls|penetration\\s*testing|ids|ips|tcp/ip|zero\\s*trust)\\b\",\n",
    "    \n",
    "    \"Data Analysis & Science\": r\"\\b(?:pandas|numpy|scikit-learn|tensorflow|power\\s*bi|excel|tableau|matplotlib)\\b\",\n",
    "    \n",
    "    \"Software Engineering (SWE)\": r\"\\b(?:software\\s*development|design\\s*patterns|oop|unit\\s*testing)\\b\",\n",
    "    \n",
    "    \"Project Management (PM)\": r\"\\b(?:agile|scrum|jira|trello|asana|kanban|scrum\\s*master|prince2|pmp|stakeholder\\s*management)\\b\",\n",
    "    \n",
    "    \"Education Certification (EC)\": r\"\\b(?:bachelor|master|phd|certified|csm|pmp|aws\\s*certified|cissp|ccna|cfa)\\b\",\n",
    "    \n",
    "    \"Soft Skills (SS)\": r\"\\b(?:communication|leadership|teamwork|problem\\s*solving|critical\\s*thinking|adaptability)\\b\"\n",
    "}\n",
    "\n",
    "test_text = \"\"\"\n",
    "JANE RODRIGUEZ\n",
    "Software Engineer\n",
    "San Francisco, CA | jane.rodriguez@email.com | (555) 123-4567 | linkedin.com/in/janerodriguez\n",
    "\n",
    "PROFESSIONAL SUMMARY\n",
    "-------------------\n",
    "Results-driven Software Engineer with 5+ years of experience developing scalable web applications. Specializing in full-stack development using Python, React, and AWS. Passionate about building intuitive user experiences and optimizing application performance.\n",
    "\n",
    "SKILLS\n",
    "------\n",
    "Programming Languages: Python, JavaScript, TypeScript, SQL, HTML/CSS\n",
    "Frameworks & Libraries: React, Django, Flask, Node.js, Express.js, Redux\n",
    "Tools & Platforms: AWS (EC2, S3, Lambda), Docker, Kubernetes, Git, GitHub Actions, Jenkins\n",
    "Databases: PostgreSQL, MongoDB, Redis\n",
    "Testing: Jest, Pytest, Selenium\n",
    "Methodologies: Agile/Scrum, Test-Driven Development, CI/CD\n",
    "\n",
    "PROFESSIONAL EXPERIENCE\n",
    "----------------------\n",
    "SENIOR SOFTWARE ENGINEER | TechSolutions Inc. | San Francisco, CA | 2021-Present\n",
    "• Developed and maintained a high-traffic e-commerce platform serving 50,000+ daily users\n",
    "• Reduced application load time by 35% through code optimization and implementing Redis caching\n",
    "• Architected and implemented microservices infrastructure, improving system scalability and fault tolerance\n",
    "• Led a team of 5 engineers to deliver new features on time with 98% test coverage\n",
    "• Mentored junior developers and conducted code reviews to ensure code quality and best practices\n",
    "\n",
    "SOFTWARE ENGINEER | DataViz Corp | Oakland, CA | 2018-2021\n",
    "• Created interactive data visualization dashboards using React and D3.js\n",
    "• Designed and implemented RESTful APIs using Django and PostgreSQL\n",
    "• Migrated legacy monolithic application to a microservices architecture\n",
    "• Automated deployment processes, reducing deployment time from 2 hours to 15 minutes\n",
    "• Implemented unit and integration testing, increasing code coverage from 60% to 90%\n",
    "\n",
    "EDUCATION\n",
    "---------\n",
    "MASTER OF SCIENCE IN COMPUTER SCIENCE | University of California, Berkeley | 2018\n",
    "• GPA: 3.8/4.0\n",
    "• Specialization: Artificial Intelligence and Machine Learning\n",
    "• Thesis: \"Optimizing Neural Networks for Mobile Applications\"\n",
    "\n",
    "BACHELOR OF SCIENCE IN COMPUTER ENGINEERING | Stanford University | 2016\n",
    "• GPA: 3.7/4.0\n",
    "• Minor in Mathematics\n",
    "• Dean's List: 6 semesters\n",
    "\n",
    "CERTIFICATIONS\n",
    "-------------\n",
    "• AWS Certified Solutions Architect – Associate\n",
    "• Google Cloud Professional Data Engineer\n",
    "• Certified Scrum Master (CSM)\n",
    "\n",
    "PROJECTS\n",
    "--------\n",
    "PERSONAL FINANCE TRACKER | github.com/janerodriguez/finance-tracker\n",
    "• Developed a full-stack application using React, Node.js, and MongoDB\n",
    "• Implemented OAuth2.0 for secure authentication and JWT for authorization\n",
    "• Created data visualization components to track spending habits and budget goals\n",
    "\n",
    "AI CHATBOT ASSISTANT | github.com/janerodriguez/ai-assistant\n",
    "• Built a conversational AI using Python, TensorFlow, and NLP techniques\n",
    "• Integrated with various APIs to provide real-time information\n",
    "• Deployed on AWS Lambda with CI/CD pipeline through GitHub Actions\n",
    "\"\"\"\n",
    "\n",
    "extracted_entities = defaultdict(set)\n",
    "#modified_text = remove_stopwords(test_text_2)\n",
    "modified_text = test_text\n",
    "\n",
    "# Apply regex patterns with wildcard matching\n",
    "for label, pattern in patterns.items():\n",
    "    # Define the replacement function inside the loop\n",
    "    # This creates a new function for each iteration\n",
    "    def replacement_func(match_obj):\n",
    "        match_text = match_obj.group(0)\n",
    "        \n",
    "        # Add the match to extracted entities\n",
    "        if isinstance(match_text, tuple):  # Handle tuple case from capture groups\n",
    "            extracted_entities[label].update(map(str.lower, match_text))\n",
    "        else:\n",
    "            extracted_entities[label].add(match_text.lower())\n",
    "            \n",
    "        # Return empty string to remove the match from the text\n",
    "        return \"\"\n",
    "    \n",
    "    # Find matches and replace them with empty string\n",
    "    modified_text = re.sub(pattern, replacement_func, modified_text, flags=re.IGNORECASE)\n",
    "\n",
    "# Print the extracted entities\n",
    "print(\"=== EXTRACTED ENTITIES ===\\n\")\n",
    "for label, entities in extracted_entities.items():\n",
    "    # Convert set to a comma-separated string for printing\n",
    "    entities_str = \", \".join(sorted(entities))\n",
    "    print(f\"{label}: {entities_str}\")\n",
    "\n",
    "# Print the leftover text\n",
    "print(\"\\n=== LEFTOVER TEXT ===\\n\")\n",
    "print(modified_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python3, sql, database administration, relational database management, aws amplify, aws cloud, aws ec2, aws snowflake, dockerized, agil\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem.porter import *\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "test = stemmer.stem(\"python3, sql, database administration, relational database management, aws amplify, aws cloud, aws ec2, aws snowflake, dockerized, agile\")\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "database administration aws\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    " \n",
    "lemmatizer = WordNetLemmatizer()\n",
    "test2 = lemmatizer.lemmatize(\"database administration aws\")\n",
    "print(test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
